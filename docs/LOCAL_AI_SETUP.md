# üîß Local AI Setup Instructions

## Pr√©-requisitos

```bash
# macOS
brew install onnxruntime
brew install wget

# Verificar instala√ß√£o
pkg-config --cflags --libs onnxruntime
```

## Download dos Modelos

```bash
cd /Users/wagnermontes/Documents/GitHub/photoguru
./scripts/download_models.sh
```

Isso vai baixar (~6GB total):
- ‚úÖ CLIP ViT-B/32 (ONNX) - 170MB - Embeddings de imagens
- ‚úÖ CLIP Text (ONNX) - 250MB - Text embeddings (opcional)
- ‚úÖ LLaVA 7B (GGUF) - 4.1GB - LLM Vision para descri√ß√µes
- ‚úÖ LLaVA Projector (GGUF) - 600MB - Vision encoder
- ‚úÖ MobileVLM 1.7B (GGUF) - 1.2GB - Alternativa mais r√°pida

## Compila√ß√£o

```bash
# Limpar build anterior
rm -rf build

# Recompilar com suporte a ONNX
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build --parallel 8
```

## Uso

### CLIP Embeddings (Instant√¢neo)
```cpp
CLIPAnalyzer clip;
clip.initialize("models/clip_vision.onnx");

auto embedding = clip.computeEmbedding(image);
// embedding = vector<float> com 512 dimens√µes
```

### LLM Analysis (Lento, ~5s)
```cpp
LlamaAnalyzer llama;
llama.initialize("models/mobilevlm-1.7b-q4.gguf");

auto result = llama.analyzeImage(imagePath);
// result.title, result.description, result.keywords
```

## Troubleshooting

### ONNX Runtime not found
```bash
# Instalar manualmente
brew install onnxruntime

# Ou apontar para instala√ß√£o customizada
export ONNXRUNTIME_ROOT=/path/to/onnxruntime
```

### Modelos n√£o encontrados
```bash
# Verificar se existem
ls -lh models/

# Re-baixar se necess√°rio
rm -rf models/*.onnx models/*.gguf
./scripts/download_models.sh
```

### Performance ruim
```bash
# Verificar se CoreML est√° sendo usado (macOS)
# Logs devem mostrar: "Using CoreML execution provider"

# Verificar se Metal est√° habilitado para llama.cpp
# Build com: make LLAMA_METAL=1
```

## Desenvolvimento

### Adicionar novo modelo ONNX
1. Converter para ONNX (PyTorch ‚Üí ONNX)
2. Salvar em `models/`
3. Criar classe wrapper herdando de `ONNXInference`
4. Implementar preprocessing espec√≠fico

### Testar performance
```bash
# Benchmark CLIP
time ./build/PhotoGuruViewer --benchmark-clip models/clip_vision.onnx test.jpg

# Benchmark LLaVA
time ./build/PhotoGuruViewer --benchmark-llama models/mobilevlm-1.7b-q4.gguf test.jpg
```

## Refer√™ncias

- [ONNX Runtime](https://onnxruntime.ai/)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [LLaVA Paper](https://arxiv.org/abs/2304.08485)
